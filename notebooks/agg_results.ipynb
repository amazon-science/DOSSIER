{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append('../')\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option('max_colwidth', 500)\n",
    "\n",
    "figure_dir = Path('./figures')\n",
    "figure_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path('/data/healthy-ml/scratch/haoran/clinical_fact_check/results/fact_check/results/eval_pipeline_claude/')\n",
    "root_dir2 = Path('/data/healthy-ml/scratch/haoran/clinical_fact_check/results/fact_check/results/eval_pipeline_codellama/')\n",
    "root_dir_llm = Path('/data/healthy-ml/scratch/haoran/clinical_fact_check/results/fact_check/results/eval_baseline_llm/')\n",
    "\n",
    "ress, argss = [], []\n",
    "for i in list(root_dir.glob('**/done')) + list(root_dir2.glob('**/done')) + list(root_dir_llm.glob('**/done')):\n",
    "    args = json.load((i.parent/'args.json').open('r'))\n",
    "        \n",
    "    res = pickle.load((i.parent/'res.pkl').open('rb')) \n",
    "    exp_name = i.parent.parent.name\n",
    "    args['exp_name'] = exp_name\n",
    "    \n",
    "    if exp_name.startswith('eval_baseline'): # llm baseline\n",
    "        args['name'] = 'baseline' + ': ' + args['llm'] + ': ' + args['select_rows']\n",
    "    else:\n",
    "        args['name'] =  args['llm'] + ': ' + args['prompt']\n",
    "    \n",
    "    ress.append(res)\n",
    "    argss.append(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064da2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = pd.read_csv(Path(argss[0]['claim_df_path'])).reset_index().rename(columns = {'index': 'claim_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1038aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055d954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, i in enumerate(ress):\n",
    "    ress[c] = (ress[c].drop(columns = ['label', 'claim'], errors = 'ignore')\n",
    "               .merge(claims, on = 'claim_id', how = 'inner')\n",
    "               .assign(prompt_type = argss[c]['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6cb610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(ress, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa40970",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7665770",
   "metadata": {},
   "source": [
    "### Accuracy based on # tables required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97abc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "srs = df.groupby(['prompt_type', 'requires_global_kg', 'num_tables_required']).apply(lambda x: (x['label'] == x['pred_label']).sum()/len(x))\n",
    "temp = srs.to_frame().reset_index().rename(columns = {0: 'Accuracy'}).pivot_table(columns = ['requires_global_kg', 'num_tables_required'], index = ['prompt_type'], values = ['Accuracy'])\n",
    "temp = temp.loc[~temp.index.str.endswith('random')]\n",
    "(temp).style.format('{:.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9ac9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "srs = df.groupby(['prompt_type']).apply(lambda x: (x['label'] == x['pred_label']).sum()/len(x))\n",
    "srs.to_frame().style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0687ec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many samples in each category?\n",
    "srs = df.groupby(['prompt_type', 'requires_global_kg', 'num_tables_required']).apply(len)\n",
    "srs.to_frame().reset_index().rename(columns = {0: '# Samples'}).pivot_table(columns = ['requires_global_kg', 'num_tables_required'], index = ['prompt_type'], values = ['# Samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c820f620",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# accuracy on NEI labels\n",
    "srs = df.query('label == \"N\"').groupby(['prompt_type', 'requires_global_kg', 'num_tables_required']).apply(lambda x: (x['label'] == x['pred_label']).sum()/len(x))\n",
    "temp = srs.to_frame().reset_index().rename(columns = {0: 'Accuracy'}).pivot_table(columns = ['requires_global_kg', 'num_tables_required'], index = ['prompt_type'], values = ['Accuracy'])\n",
    "temp = temp.loc[~temp.index.str.endswith('random')]\n",
    "temp.to_pickle('result2_nei.pkl')\n",
    "temp.style.format('{:.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0067702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on non-NEI labels\n",
    "srs = df.query('label != \"N\"').groupby(['prompt_type', 'requires_global_kg', 'num_tables_required']).apply(lambda x: (x['label'] == x['pred_label']).sum()/len(x))\n",
    "temp = srs.to_frame().reset_index().rename(columns = {0: 'Accuracy'}).pivot_table(columns = ['requires_global_kg', 'num_tables_required'], index = ['prompt_type'], values = ['Accuracy'])\n",
    "temp = temp.loc[~temp.index.str.endswith('random')]\n",
    "temp.to_pickle('result2_tf.pkl')\n",
    "temp.style.format('{:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91b106",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7ca74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in df['prompt_type'].unique():\n",
    "    print(i)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix(df.loc[df.prompt_type == i, 'label'], df.loc[df.prompt_type == i, 'pred_label'], labels = ['T', 'F', 'N']),\n",
    "    display_labels = ['T', 'F', 'N'])\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8822622f",
   "metadata": {},
   "source": [
    "### Committed predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b4ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % non-NEI predictions\n",
    "srs = df.groupby(['prompt_type', 'requires_global_kg', 'num_tables_required']).apply(lambda x: ( (x['pred_label'] != 'N')).sum()/len(x))\n",
    "srs.to_frame().reset_index().rename(columns = {0: '# Samples'}).pivot_table(columns = ['requires_global_kg', 'num_tables_required'], index = ['prompt_type'], values = ['# Samples']).style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b288d9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy when predict non-NEI\n",
    "srs = df.groupby(['prompt_type', 'requires_global_kg', 'num_tables_required']).apply(lambda x: ((x['label'] == x['pred_label']) & (x['pred_label'] != 'N')).sum()/(x['pred_label'] != 'N').sum())\n",
    "srs.to_frame().reset_index().rename(columns = {0: 'Accuracy'}).pivot_table(columns = ['requires_global_kg', 'num_tables_required'], index = ['prompt_type'], values = ['Accuracy']).style.format('{:.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
